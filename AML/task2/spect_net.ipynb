{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import os\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torchvision.models import efficientnet_v2_m, EfficientNet_V2_M_Weights\n",
    "from sklearn.preprocessing import normalize\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self,dataframe,label):\n",
    "        self.data = dataframe\n",
    "        self.label = label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return nn.tensor(self.data[idx]),self.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectograms_orig = pd.read_csv('spectograms_train.csv')\n",
    "y_train_orig = pd.read_csv('y_train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(dl_train):\n",
    "    \"\"\"\n",
    "    Transform, resize and normalize the images and then use a pretrained model to extract\n",
    "    the embeddings.\n",
    "    \"\"\"\n",
    "    embedding_size = 1000  # Dummy variable, replace with the actual embedding size once you pick your model\n",
    "    batch_size = 16\n",
    "\n",
    "    # TODO: define a transform to pre-process the images\n",
    "    train_transforms = EfficientNet_V2_M_Weights.DEFAULT.transforms()  # transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    train_dataset = datasets.ImageFolder(root=\"dataset/\", transform=train_transforms)\n",
    "    \n",
    "    print((train_dataset[1][1]))\n",
    "    # Hint: adjust batch_size and num_workers to your PC configuration, so that you don't run out of memory\n",
    "    train_loader = dl_train\n",
    "\n",
    "    # TODO: define a model for extraction of the embeddings (Hint: load a pretrained model,\n",
    "    #  more info here: https://pytorch.org/vision/stable/models.html)\n",
    "    \n",
    "    model = efficientnet_v2_m(weights=EfficientNet_V2_M_Weights.DEFAULT)\n",
    "\n",
    "    embeddings = np.array([], dtype=np.float32).reshape(0, embedding_size)\n",
    "    num_images = len(train_dataset)\n",
    "    # embeddings = np.zeros((num_images, embedding_size))\n",
    "    # TODO: Use the model to extract the embeddings. Hint: remove the last layers of the\n",
    "    # model to access the embeddings the model generates.\n",
    "\n",
    "    # model = torch.nn.Sequential(*(list(model.children())[:-1]))\n",
    "    model.to(device)\n",
    "    idx = 0\n",
    "    with torch.no_grad():\n",
    "        for batch, _ in train_loader:\n",
    "            batch = batch.cuda()\n",
    "            model.eval()\n",
    "            preds = model.forward(batch).cpu().numpy()\n",
    "            preds = preds.reshape((int(preds.size / embedding_size), embedding_size))\n",
    "            embeddings = np.concatenate((embeddings, preds), axis=0)\n",
    "            idx += batch_size\n",
    "            print(f\"{idx / num_images * 100} %\")\n",
    "\n",
    "    np.save(\"dataset/embeddings.npy\", embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(spectograms_orig, y_train_orig)\n",
    "train_dataset = MyDataset(X_train,y_train)\n",
    "test_dataset = MyDataset(X_test,y_test)\n",
    "\n",
    "dl_train = DataLoader(train_dataset,batch_size=64,shuffle=True,num_workers=4)\n",
    "dl_test = DataLoader(test_dataset,batch_size=64,shuffle=True,num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "generate_embeddings(dl_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
